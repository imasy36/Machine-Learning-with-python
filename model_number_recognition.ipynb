{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_number_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnfnUbtsFEJR097+1aYfG5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imasy36/Machine-Learning-with-python/blob/master/model_number_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIG-WBx4nMix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first deep learning model for recognising handwritten numbers\n",
        "# author @imasy36"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PwaQbLunm2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6figyfw8yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting data\n",
        "import torch \n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lud0rhspzoRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
        "traindata = datasets.MNIST('MNIST_data/',train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(traindata, batch_size=64, shuffle=True)\n",
        "testdata = datasets.MNIST('MNIST_data/',train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testdata, batch_size=64, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXgUrthOj1Xg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "23969062-5d12-443c-d5c7-7de1c455ab9c"
      },
      "source": [
        "# verifying data\n",
        "iter_var = iter(trainloader)\n",
        "images, labels = iter_var.next()\n",
        "plt.imshow(images[4].numpy().squeeze())\n",
        "print(labels[4])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG0RvDORnuou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building model\n",
        "from collections import OrderedDict\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('InputLayer',nn.Linear(784,128)),\n",
        "          ('Relu1',nn.ReLU()),\n",
        "          ('HiddenLayer',nn.Linear(128,64)),\n",
        "          ('Relu2',nn.ReLU()),\n",
        "          ('OutputLayer',nn.Linear(64,10)),\n",
        "          ('Softmax',nn.Softmax(dim=1)),                    \n",
        "]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhZhHhzhroxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6VaWwCrqJl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "005ee3fc-cee7-49b7-83a5-2da48658081a"
      },
      "source": [
        "# training\n",
        "epochs = 5\n",
        "print_every = 100\n",
        "running_loss = 0\n",
        "step = 0\n",
        "for e in range(epochs):\n",
        "  for images, labels in trainloader:\n",
        "    step += 1\n",
        "    images.resize_(images.shape[0], 784)\n",
        "    optimizer.zero_grad()\n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "    if step % print_every == 0:\n",
        "      print('epocs {}/{} with running loss {}'.format(e+1,epochs,running_loss/print_every))\n",
        "      running_loss = 0\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epocs 1/5 with running loss 1.5215475475788116\n",
            "epocs 1/5 with running loss 1.522088692188263\n",
            "epocs 1/5 with running loss 1.5218338572978973\n",
            "epocs 1/5 with running loss 1.5207372152805327\n",
            "epocs 1/5 with running loss 1.5231573331356048\n",
            "epocs 1/5 with running loss 1.5214116942882538\n",
            "epocs 1/5 with running loss 1.5171041512489318\n",
            "epocs 1/5 with running loss 1.524249793291092\n",
            "epocs 1/5 with running loss 1.5193092346191406\n",
            "epocs 2/5 with running loss 1.5190738224983216\n",
            "epocs 2/5 with running loss 1.521481727361679\n",
            "epocs 2/5 with running loss 1.5204598367214204\n",
            "epocs 2/5 with running loss 1.5226190876960755\n",
            "epocs 2/5 with running loss 1.519880405664444\n",
            "epocs 2/5 with running loss 1.5178765118122102\n",
            "epocs 2/5 with running loss 1.5151987397670745\n",
            "epocs 2/5 with running loss 1.524444967508316\n",
            "epocs 2/5 with running loss 1.5188373696804047\n",
            "epocs 3/5 with running loss 1.5193113279342652\n",
            "epocs 3/5 with running loss 1.5196504044532775\n",
            "epocs 3/5 with running loss 1.519047212600708\n",
            "epocs 3/5 with running loss 1.5163840448856354\n",
            "epocs 3/5 with running loss 1.520552726984024\n",
            "epocs 3/5 with running loss 1.5214516246318817\n",
            "epocs 3/5 with running loss 1.520641815662384\n",
            "epocs 3/5 with running loss 1.514888973236084\n",
            "epocs 3/5 with running loss 1.5186027431488036\n",
            "epocs 3/5 with running loss 1.5198180603981017\n",
            "epocs 4/5 with running loss 1.5156394481658935\n",
            "epocs 4/5 with running loss 1.5195709514617919\n",
            "epocs 4/5 with running loss 1.5246417117118836\n",
            "epocs 4/5 with running loss 1.516851645708084\n",
            "epocs 4/5 with running loss 1.5214129829406737\n",
            "epocs 4/5 with running loss 1.5180045127868653\n",
            "epocs 4/5 with running loss 1.5184248328208922\n",
            "epocs 4/5 with running loss 1.5186471354961395\n",
            "epocs 4/5 with running loss 1.5109813272953034\n",
            "epocs 5/5 with running loss 1.5160889303684235\n",
            "epocs 5/5 with running loss 1.5098305118083954\n",
            "epocs 5/5 with running loss 1.5175415241718293\n",
            "epocs 5/5 with running loss 1.5192866802215577\n",
            "epocs 5/5 with running loss 1.5179986786842345\n",
            "epocs 5/5 with running loss 1.5172114419937133\n",
            "epocs 5/5 with running loss 1.5195459342002868\n",
            "epocs 5/5 with running loss 1.5207921707630156\n",
            "epocs 5/5 with running loss 1.5154809367656707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5DHtzmds8aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "356eda48-8d56-44e3-bf67-d865e134404b"
      },
      "source": [
        "temp = iter(testloader)\n",
        "images, labels = temp.next()\n",
        "with torch.no_grad():\n",
        "  out = model.forward(images.resize_(images.shape[0],784))\n",
        "ps= nn.functional.softmax(out,dim=1)\n",
        "print(\"label - {}\".format(labels))\n",
        "equal = (labels.data == ps.max(1)[1])\n",
        "accuracy = equal.type(torch.FloatTensor).mean()\n",
        "print(\"Predictions - {}\".format(ps.max(1)[1]))\n",
        "print(accuracy)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label - tensor([2, 8, 6, 3, 3, 7, 8, 3, 3, 7, 4, 7, 8, 4, 6, 5, 7, 2, 0, 2, 8, 5, 1, 4,\n",
            "        6, 8, 3, 3, 9, 3, 5, 7, 0, 0, 8, 3, 8, 2, 0, 6, 2, 9, 3, 8, 7, 1, 7, 7,\n",
            "        8, 2, 0, 1, 6, 0, 1, 7, 0, 0, 1, 3, 2, 0, 7, 7])\n",
            "Predictions - tensor([2, 1, 6, 7, 3, 7, 1, 3, 3, 7, 4, 7, 8, 4, 6, 5, 7, 2, 0, 2, 8, 5, 1, 4,\n",
            "        5, 8, 3, 3, 9, 3, 5, 7, 0, 0, 8, 3, 8, 2, 0, 5, 2, 9, 3, 8, 2, 1, 7, 7,\n",
            "        8, 2, 0, 1, 6, 0, 1, 2, 0, 0, 1, 3, 2, 0, 7, 7])\n",
            "tensor(0.8906)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW9wHcastiDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9d3183b-c22f-4a99-d350-b87c646f00d8"
      },
      "source": [
        "#testing data\n",
        "print_every = 50\n",
        "acc = 0\n",
        "step = 0\n",
        "for images, labels in testloader:\n",
        "  step+=1\n",
        "  images = images.resize_(images.shape[0],784)\n",
        "  with torch.no_grad():\n",
        "    output = model.forward(images)\n",
        "  ps = nn.functional.softmax(output,dim=1)\n",
        "  equal = (labels.data == ps.max(1)[1])\n",
        "  acc += equal.type(torch.FloatTensor).mean()\n",
        "  if step % print_every == 0:\n",
        "    print(\"Accuracy - {} \".format(acc/print_every))\n",
        "    acc = 0"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy - 0.9378125071525574 \n",
            "Accuracy - 0.9518749713897705 \n",
            "Accuracy - 0.9440624713897705 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCG-CT6GyaYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3cfb709a-fecf-4aa4-de06-6d0f127eb4ea"
      },
      "source": [
        "torch.save(model.state_dict(),'recognition.pth')\n",
        "from google.colab import files\n",
        "files.download('recognition.pth')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_853e0df4-12c0-4540-84fa-93a4e7584819\", \"recognition.pth\", 439879)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}